{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene-Prediction-in-Metagenomics-Fragments\n",
    "Written by: Vignesh Ravindranath, Shawn Huang\n",
    "\n",
    "    This project was based on the 2008 paper 'Gene prediction in metagenomic fragments: A large scale machine learning approach' by Hoff et at (see link below). The purpose of the project is to gain a deeper understanding of machine learning approaches and bioinformatics concepts.\n",
    "    The project consists of three main steps:\n",
    "    1) Feature engineering/extraction\n",
    "    2) Linear Discriminant training on high-dimentional features\n",
    "    3) Binary classification neural network for coding/noncoding gene prediction\n",
    "    \n",
    "    In the first step, features such as monocodon (tricodon) usage, dicodon (hexcodon) usage, translation initiation sites (TIS), and GC content must be extracted from prokaryotic genomes. Monocodon and dicodon usage refer to the frequence of codons and dicodons (6 base pairs) in coding and noncoding regions. Coding proteins often have a TIS upstream of the start codon. These TIS patterns are extracted by comparing up and downstream regions for positive TIS candidates (true start codons in coding sequences) to negative TIS candidates (in-frame start codons within coding sequences). Lastly, it is well known that the GC content between coding and noncoding regions vary. \n",
    "    In the second step, linear discriminants are derived to reduce the dimensionality of the extracted features. The individual features (excluding GC content) are taken as multivariate linear regression problems and the Normal Equation is utilized to compute the weights (coefficient) matrix for each feature. \n",
    "    In the last step, a neural network is trained on fragmented data.\n",
    "    \n",
    "    \n",
    "    Summary of features:\n",
    "    x1 - tricodon       - (n,64) table --reduced to a weights matrix of (64,1)\n",
    "    x2 - hexcodon       - (n,4096) table --reduced to a weights matrix of (4096,1)\n",
    "    x3 - positive TIS   - (n,58,64 == n,3712) table --reduced to a weights matrix of (3712,1)\n",
    "    x4 - negative TIS   - (m,58,64 == m,3712) table --reduced to a weights matrix of (3712,1)\n",
    "    x5 - complete seq   - 1 if fragment contains a complete gene, else 0\n",
    "    x6 - incomplete seq - 0 if fragment contains a complete gene, else 1\n",
    "    x7 - GC content     - (n,1) column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference Gene Prediciton Paper (Hoff et al.):\n",
    "- https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-217\n",
    "\n",
    "Genbank link (A fulgidus - test prokaryotic genome): \n",
    "- https://www.ncbi.nlm.nih.gov/nuccore/NC_000917\n",
    "\n",
    "Biopython references\n",
    "- http://biopython.org/DIST/docs/tutorial/Tutorial.html\n",
    "- https://biopython.org/wiki/Intergenic_regions\n",
    "- https://biopython.org/docs/dev/api/Bio.SeqFeature.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import itertools\n",
    "import textwrap\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio import Entrez\n",
    "Entrez.email = \"vignesh.ravindranath@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched NC_000917 GenBank records\n",
      "Fetched NC_000917 FASTA sequence\n"
     ]
    }
   ],
   "source": [
    "prokaryote_id = 'NC_000917'\n",
    "\n",
    "# get seq_records (features) from GenBank file\n",
    "handle = Entrez.efetch(db=\"sequences\", id=prokaryote_id, rettype=\"gbwithparts\", retmode=\"text\")\n",
    "seq_record = SeqIO.read(handle, \"gb\")\n",
    "handle.close()\n",
    "print(f'Fetched {prokaryote_id} GenBank records')\n",
    "\n",
    "# get full sequence from FASTA file\n",
    "handle = Entrez.efetch(db=\"sequences\", id=prokaryote_id, rettype=\"fasta\", retmode=\"text\")\n",
    "sequence = SeqIO.read(handle, \"fasta\")\n",
    "handle.close()\n",
    "print(f'Fetched {prokaryote_id} FASTA sequence')\n",
    "\n",
    "dna = [sequence, sequence.reverse_complement()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring SeqRecord Data and Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2473\n"
     ]
    }
   ],
   "source": [
    "cds = []\n",
    "\n",
    "for feature in seq_record.features:\n",
    "    if feature.type == 'CDS':\n",
    "        cds.append(feature)\n",
    "        \n",
    "print(len(cds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: CDS\n",
      "location: [4289:4784](+)\n",
      "qualifiers:\n",
      "    Key: codon_start, Value: ['1']\n",
      "    Key: db_xref, Value: ['GeneID:1483212']\n",
      "    Key: inference, Value: ['COORDINATES: protein motif:HMM:NF012415.1']\n",
      "    Key: locus_tag, Value: ['AF_RS00005']\n",
      "    Key: note, Value: ['Derived by automated computational analysis using gene prediction method: Protein Homology.']\n",
      "    Key: old_locus_tag, Value: ['AF0003', 'AF_0003']\n",
      "    Key: product, Value: ['CAP domain-containing protein']\n",
      "    Key: protein_id, Value: ['WP_010877517.1']\n",
      "    Key: transl_table, Value: ['11']\n",
      "    Key: translation, Value: ['MKETIQLAIGVMLLAMLGCYIYITEFYHYESTEESSKAAIEYLNQLRAQNGLPPVKWNKTLYEFALERLEDMHERGYYSHYDPVTHETLIYRYVEGYVGECILNGVRGTNLLSNGLQSLFGYEEEAIDIWSKSTMHKLILTDKRFTDAAVACKYDMCVLIMTGG']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC_000917.1\n"
     ]
    }
   ],
   "source": [
    "print(seq_record.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4289\n",
      "4784\n",
      "1\n",
      "AF_RS00005\n",
      "MKETIQLAIGVMLLAMLGCYIYITEFYHYESTEESSKAAIEYLNQLRAQNGLPPVKWNKTLYEFALERLEDMHERGYYSHYDPVTHETLIYRYVEGYVGECILNGVRGTNLLSNGLQSLFGYEEEAIDIWSKSTMHKLILTDKRFTDAAVACKYDMCVLIMTGG\n",
      "---check if using correct dna strand\n",
      "MKETIQLAIGVMLLAMLGCYIYITEFYHYESTEESSKAAIEYLNQLRAQNGLPPVKWNKTLYEFALERLEDMHERGYYSHYDPVTHETLIYRYVEGYVGECILNGVRGTNLLSNGLQSLFGYEEEAIDIWSKSTMHKLILTDKRFTDAAVACKYDMCVLIMTGG*\n"
     ]
    }
   ],
   "source": [
    "# Coding sequence on coding strand (+1)\n",
    "\n",
    "print(cds[0].location.start.position)\n",
    "print(cds[0].location.end.position)\n",
    "print(cds[0].strand)\n",
    "print(cds[0].qualifiers['locus_tag'][0])\n",
    "print(cds[0].qualifiers['translation'][0])\n",
    "\n",
    "start = cds[0].location.start.position\n",
    "end = cds[0].location.end.position\n",
    "\n",
    "print('---check if using correct dna strand')\n",
    "seq0 = dna[0][start:end].seq\n",
    "pro = seq0.translate()\n",
    "print(pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44802\n",
      "45561\n",
      "-1\n",
      "AF_RS00195\n",
      "MSGYLRKRDVIITMTQFEFKQRYRGTALGLIWSLLAPFLLALVLFLVFRNMFSWVENFAAYVLVGVFVFRFFQVATSVGMHTIVGKSHLVTKTNIDRELLPLATTLSYGMSSFLEILVIVPIVHVLGGNVGFTILFLPVIHFVYIIFIFGLNLFLSSLMVYFRDLNQIWEVITNVIFFASPIVYPLTMIPESYREMYMLNPIACIIEIYRGILMENQILLEKFIYFLLISLALTFAGQLFFRRMQKRFGEVL\n",
      "---check if using correct dna strand\n",
      "MSGYLRKRDVIITMTQFEFKQRYRGTALGLIWSLLAPFLLALVLFLVFRNMFSWVENFAAYVLVGVFVFRFFQVATSVGMHTIVGKSHLVTKTNIDRELLPLATTLSYGMSSFLEILVIVPIVHVLGGNVGFTILFLPVIHFVYIIFIFGLNLFLSSLMVYFRDLNQIWEVITNVIFFASPIVYPLTMIPESYREMYMLNPIACIIEIYRGILMENQILLEKFIYFLLISLALTFAGQLFFRRMQKRFGEVL*\n"
     ]
    }
   ],
   "source": [
    "# Coding sequence on complementary strand (-1)\n",
    "\n",
    "print(cds[39].location.start.position)\n",
    "print(cds[39].location.end.position)\n",
    "print(cds[39].strand)\n",
    "print(cds[39].qualifiers['locus_tag'][0])\n",
    "print(cds[39].qualifiers['translation'][0])\n",
    "\n",
    "start = cds[39].location.start.position\n",
    "end = cds[39].location.end.position\n",
    "\n",
    "print('---check if using correct dna strand')\n",
    "seq39 = dna[1][::-1][start:end][::-1].seq\n",
    "pro = seq39.translate()\n",
    "print(pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Coding Sequences (CDS) or Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2473\n"
     ]
    }
   ],
   "source": [
    "# Get positive ORFs (coding sequences (CDS) or genes)\n",
    "l_min = sys.maxsize\n",
    "cds = []\n",
    "for feature in seq_record.features:\n",
    "    if feature.type == 'CDS':\n",
    "        tag    = feature.qualifiers['locus_tag'][0]\n",
    "        start  = feature.location.start.position\n",
    "        end    = feature.location.end.position\n",
    "        strand = feature.strand\n",
    "        seq    = dna[0][start:end] if strand == 1 else dna[1][::-1][start:end][::-1]\n",
    "\n",
    "        # update min\n",
    "        if len(seq) < l_min:\n",
    "            l_min = len(seq)\n",
    "\n",
    "        f = [SeqFeature(FeatureLocation(start,end,strand), type=\"CDS\")]\n",
    "        r = SeqRecord(seq.seq, name=tag, id=prokaryote_id, features=f)\n",
    "        cds.append(r)\n",
    "        \n",
    "print(len(cds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: NC_000917\n",
      "Name: AF_RS00005\n",
      "Description: <unknown description>\n",
      "Number of features: 1\n",
      "Seq('ATGAAAGAGACGATTCAGCTTGCTATAGGGGTGATGCTGTTGGCCATGCTCGGT...TGA')\n"
     ]
    }
   ],
   "source": [
    "print(cds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: CDS\n",
      "location: [4289:4784](+)\n",
      "qualifiers:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cds[0].features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Longest Open Reading Frame (ORF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prokaryotes have may have alternate start codons\n",
    "START_CODONS = ['ATG','CTG','GTG','TTG']\n",
    "STOP_CODONS = ['TAG','TGA','TAA']\n",
    "    \n",
    "def longest_orf(seq):\n",
    "    all_starts = []\n",
    "    for s in START_CODONS:\n",
    "        # Find positions of all start codons in sequence\n",
    "        matches = re.finditer(s, str(seq))\n",
    "        matches_positions = [match.start() for match in matches]\n",
    "        all_starts.extend(matches_positions)\n",
    "    all_starts = sorted(all_starts)\n",
    "\n",
    "    all_stops = []                                      \n",
    "    for e in STOP_CODONS:\n",
    "        # Find positions of all stop codons in sequence\n",
    "        matches = re.finditer(e, str(seq))\n",
    "        matches_positions = [match.start() for match in matches]\n",
    "        all_stops.extend(matches_positions)\n",
    "    all_stops = sorted(all_stops)\n",
    "\n",
    "    # find largest ORF\n",
    "    for s in all_starts:\n",
    "        for e in all_stops[::-1]:\n",
    "            if (e >= s) and ((e-s)%3 == 0):\n",
    "                return [s,e+3]\n",
    "            \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATGAAAGAGACGATTCAGCTTGCTATAGGGGTGATGCTGTTGGCCATGCTCGGTTGCTACATCTACATTACTGAGTTCTATCACTACGAATCAACTGAAGAGAGCTCAAAAGCTGCGATTGAATATTTGAATCAGCTTAGAGCTCAGAATGGCCTGCCTCCTGTAAAGTGGAATAAAACTCTTTACGAGTTTGCGCTGGAAAGGCTTGAAGATATGCATGAAAGAGGCTATTACAGTCATTATGACCCTGTTACGCATGAGACGCTGATTTACAGATATGTTGAGGGGTATGTTGGAGAGTGTATCTTGAATGGTGTAAGAGGTACAAATCTTCTCTCCAATGGGCTTCAGTCATTATTTGGCTATGAAGAAGAAGCTATAGATATCTGGTCTAAAAGCACCATGCACAAACTCATTCTCACTGATAAACGCTTCACAGATGCCGCTGTAGCCTGCAAGTACGACATGTGTGTTTTGATTATGACGGGTGGTTGA\n",
      "\n",
      "ATGAAAGAGACGATTCAGCTTGCTATAGGGGTGATGCTGTTGGCCATGCTCGGTTGCTACATCTACATTACTGAGTTCTATCACTACGAATCAACTGAAGAGAGCTCAAAAGCTGCGATTGAATATTTGAATCAGCTTAGAGCTCAGAATGGCCTGCCTCCTGTAAAGTGGAATAAAACTCTTTACGAGTTTGCGCTGGAAAGGCTTGAAGATATGCATGAAAGAGGCTATTACAGTCATTATGACCCTGTTACGCATGAGACGCTGATTTACAGATATGTTGAGGGGTATGTTGGAGAGTGTATCTTGAATGGTGTAAGAGGTACAAATCTTCTCTCCAATGGGCTTCAGTCATTATTTGGCTATGAAGAAGAAGCTATAGATATCTGGTCTAAAAGCACCATGCACAAACTCATTCTCACTGATAAACGCTTCACAGATGCCGCTGTAGCCTGCAAGTACGACATGTGTGTTTTGATTATGACGGGTGGTTGA\n"
     ]
    }
   ],
   "source": [
    "start = cds[0].features[0].location.start.position\n",
    "end = cds[0].features[0].location.end.position\n",
    "test = dna[0][start:end].seq\n",
    "\n",
    "orf = longest_orf(test)\n",
    "\n",
    "print(test)\n",
    "print()\n",
    "print(dna[0][orf[0]+start:orf[1]+start].seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATGTTTATGGGGTAG\n"
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "#        AAA ATG TTT ATG GGG TAG \n",
    "test2 = Seq('AAAATGTTTATGGGGTAG')\n",
    "\n",
    "# result:    ATG TTT ATG GGG TAG\n",
    "orf = longest_orf(test2)\n",
    "print(test2[orf[0]:orf[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Noncoding Sequences (NCS) in Interregions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find interregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interregions(coding_records):\n",
    "    cds_list_plus = []\n",
    "    cds_list_minus = []\n",
    "    intergenic_records = []\n",
    "    \n",
    "    initials = coding_records[0].name[0:2]\n",
    "    prokaryote_id = seq_record.id\n",
    "\n",
    "    # Loop over the genome file, get the CDS features on each of the strands\n",
    "    for record in coding_records:\n",
    "        feature = record.features[0]\n",
    "        mystart = feature.location.start.position\n",
    "        myend = feature.location.end.position\n",
    "        if feature.strand == -1:\n",
    "            cds_list_minus.append((mystart,myend,-1))\n",
    "        elif feature.strand == 1:\n",
    "            cds_list_plus.append((mystart,myend,1))\n",
    "        else:\n",
    "            sys.stderr.write(\"No strand indicated %d-%d. Assuming +\\n\" %(mystart, myend))\n",
    "            cds_list_plus.append((mystart,myend,1))\n",
    "    for i,pospair in enumerate(cds_list_plus[1:]):\n",
    "        # Compare current start position to previous end position\n",
    "        last_end = cds_list_plus[i][1]\n",
    "        this_start = pospair[0]\n",
    "        if this_start - last_end >= 1:\n",
    "            intergene_seq = seq_record.seq[last_end:this_start]\n",
    "            strand_string = +1\n",
    "            name = initials + '_NC' + str(i).zfill(5)\n",
    "            feature = [SeqFeature(FeatureLocation(last_end+1,this_start,strand_string), type='interregion')]\n",
    "            intergenic_records.append(SeqRecord(intergene_seq, name=prokaryote_id, id=name, features=feature))\n",
    "    buffer = i\n",
    "    for i,pospair in enumerate(cds_list_minus[1:]):\n",
    "        last_end = cds_list_minus[i][1]\n",
    "        this_start = pospair[0]\n",
    "        if this_start - last_end >= 1:\n",
    "            intergene_seq = seq_record.seq[last_end:this_start]\n",
    "            strand_string = -1\n",
    "            name = initials + '_NC' + str(i+buffer).zfill(5)\n",
    "            feature = [SeqFeature(FeatureLocation(last_end+1,this_start,strand_string), type='interregion')]\n",
    "            intergenic_records.append(SeqRecord(intergene_seq, name=prokaryote_id, id=name, features=feature))\n",
    "    return intergenic_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "interregions = get_interregions(cds)\n",
    "print(len(interregions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: AF_NC00000\n",
      "Name: NC_000917.1\n",
      "Description: <unknown description>\n",
      "Number of features: 1\n",
      "Seq('GGTGTTCAGAAAAAAGAGGAAAAGTAAAAAACAATTGCTGCGATAATCGTTTTT...CCA')\n",
      "type: interregion\n",
      "location: [4785:5050](+)\n",
      "qualifiers:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(interregions[0])\n",
    "print(interregions[0].features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find longest ORF in interregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF_NC00000\n",
      "GTGTTCAGAAAAAAGAGGAAAAGTAAAAAACAATTGCTGCGATAATCGTTTTTGCCGGCGTTTTTTGAAATCAGACTAAAGTGGGATTACGTAAATTTATTTGTGGAAAGTGTGACAAGGAAACAAAACTCAGACCGACGAGAGTTTAAAACCGCCTAAAGCTCTTCTCCAGCAAATCCACCACCAAATTTATTCATTAAGCTTTAACCGTTTAAAAATCCCCAAACGCCCAAACCTTAA\n"
     ]
    }
   ],
   "source": [
    "test3 = interregions[0].seq\n",
    "orf = longest_orf(test3)\n",
    "print(interregions[0].id)\n",
    "print(test3[orf[0]:orf[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF_NC00002\n",
      "TTGTTATGAACTGATTCATAA\n"
     ]
    }
   ],
   "source": [
    "test4 = interregions[2].seq\n",
    "orf = longest_orf(test4)\n",
    "print(interregions[2].id)\n",
    "print(test4[orf[0]:orf[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find in-frame ORFs - orf-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_CODONS = ['ATG','CTG','GTG','TTG']\n",
    "STOP_CODONS = ['TAG','TGA','TAA']\n",
    "\n",
    "def codon_pos(seq, codon_list):\n",
    "    pos = []\n",
    "    for codon in codon_list:\n",
    "        matches = re.finditer(codon, str(seq))\n",
    "        matches_positions = [match.start() for match in matches]\n",
    "        pos.extend(matches_positions)\n",
    "    return sorted(pos)\n",
    "\n",
    "'''\n",
    "Input: Bio.Seq.Seq\n",
    "Output: returns start and end position of longest orf in a sequence\n",
    "'''\n",
    "def longest_orf(seq):\n",
    "    all_starts = codon_pos(seq, START_CODONS)\n",
    "    all_stops  = codon_pos(seq, STOP_CODONS)\n",
    "           \n",
    "    for s in all_starts:\n",
    "        for e in all_stops[::-1]:\n",
    "            if (e >= s) and ((e-s)%3 == 0):\n",
    "                return [s,e+3]\n",
    "    return []\n",
    "\n",
    "'''\n",
    "Input: Bio.Seq.Seq\n",
    "Output: returns all in-frame start codons within an ORF sequence\n",
    "'''\n",
    "def orf_finder(orf_seq):\n",
    "    all_starts = codon_pos(orf_seq, START_CODONS)\n",
    "\n",
    "    # find all ORF\n",
    "    orfs = []           \n",
    "    for s in all_starts:\n",
    "        if s%3 == 0:\n",
    "            orfs.append([s,len(orf_seq)])\n",
    "    return orfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 495], [30, 495], [33, 495], [36, 495], [39, 495]]\n",
      "ATG\n",
      "GTG\n",
      "ATG\n",
      "CTG\n",
      "TTG\n"
     ]
    }
   ],
   "source": [
    "test5 = cds[0].seq\n",
    "\n",
    "orfs = orf_finder(test5)\n",
    "print(orfs[0:5])\n",
    "\n",
    "for orf in orfs[0:5]:\n",
    "    print(test5[orf[0]:orf[0]+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 240], [33, 240], [36, 240], [51, 240], [102, 240]]\n",
      "GTG\n",
      "TTG\n",
      "CTG\n",
      "TTG\n",
      "GTG\n"
     ]
    }
   ],
   "source": [
    "test6 = ncs[0].seq\n",
    "\n",
    "orfs = orf_finder(test6)\n",
    "print(orfs)\n",
    "\n",
    "for orf in orfs:\n",
    "    print(test6[orf[0]:orf[0]+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preprocessing ORFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interregions(coding_records):\n",
    "    cds_list_plus = []\n",
    "    cds_list_minus = []\n",
    "    intergenic_records = []\n",
    "    \n",
    "    initials = coding_records[0].name[0:2]\n",
    "    prokaryote_id = coding_records[0].id\n",
    "\n",
    "    # Loop over the genome file, get the CDS features on each of the strands\n",
    "    for record in coding_records:\n",
    "        feature = record.features[0]\n",
    "        mystart = feature.location.start.position\n",
    "        myend = feature.location.end.position\n",
    "        if feature.strand == -1:\n",
    "            cds_list_minus.append((mystart,myend,-1))\n",
    "        elif feature.strand == 1:\n",
    "            cds_list_plus.append((mystart,myend,1))\n",
    "        else:\n",
    "            sys.stderr.write(\"No strand indicated %d-%d. Assuming +\\n\" %(mystart, myend))\n",
    "            cds_list_plus.append((mystart,myend,1))\n",
    "    for i,pospair in enumerate(cds_list_plus[1:]):\n",
    "        # Compare current start position to previous end position\n",
    "        last_end = cds_list_plus[i][1]\n",
    "        this_start = pospair[0]\n",
    "        if this_start - last_end >= 1:\n",
    "            intergene_seq = seq_record.seq[last_end:this_start]\n",
    "            strand_string = +1\n",
    "            tag = initials + '_NC' + str(i).zfill(5)\n",
    "            feature = [SeqFeature(FeatureLocation(last_end+1,this_start,strand_string), type='interregion')]\n",
    "            intergenic_records.append(SeqRecord(intergene_seq, name=tag, id=prokaryote_id, features=feature))\n",
    "    buffer = i\n",
    "    for i,pospair in enumerate(cds_list_minus[1:]):\n",
    "        last_end = cds_list_minus[i][1]\n",
    "        this_start = pospair[0]\n",
    "        if this_start - last_end >= 1:\n",
    "            intergene_seq = seq_record.seq[last_end:this_start]\n",
    "            strand_string = -1\n",
    "            tag = initials + '_NC' + str(i+buffer).zfill(5)\n",
    "            feature = [SeqFeature(FeatureLocation(last_end+1,this_start,strand_string), type='interregion')]\n",
    "            intergenic_records.append(SeqRecord(intergene_seq, name=tag, id=prokaryote_id, features=feature))\n",
    "    return intergenic_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_CODONS = ['ATG','CTG','GTG','TTG']\n",
    "STOP_CODONS = ['TAG','TGA','TAA']\n",
    "\n",
    "def codon_pos(seq, codon_list):\n",
    "    pos = []\n",
    "    for codon in codon_list:\n",
    "        matches = re.finditer(codon, str(seq))\n",
    "        matches_positions = [match.start() for match in matches]\n",
    "        pos.extend(matches_positions)\n",
    "    return sorted(pos)\n",
    "\n",
    "'''\n",
    "Input: Bio.Seq.Seq\n",
    "Output: returns start and end position of longest orf in a sequence\n",
    "'''\n",
    "def longest_orf(seq):\n",
    "    all_starts = codon_pos(seq, START_CODONS)\n",
    "    all_stops  = codon_pos(seq, STOP_CODONS)\n",
    "\n",
    "    orfs = []\n",
    "    found = False;            \n",
    "    for s in all_starts:\n",
    "        for e in all_stops[::-1]:\n",
    "            if (e >= s) and ((e-s)%3 == 0):\n",
    "                found = True; orfs = [s,e+3];\n",
    "                break\n",
    "        if found: break\n",
    "            \n",
    "    return orfs\n",
    "\n",
    "'''\n",
    "Input: Bio.Seq.Seq\n",
    "Output: returns all in-frame start codons within an ORF sequence\n",
    "'''\n",
    "def orf_finder(orf_seq):\n",
    "    all_starts = codon_pos(orf_seq, START_CODONS)\n",
    "\n",
    "    # find all ORF\n",
    "    orfs = []\n",
    "    e = len(orf_seq)\n",
    "    for s in all_starts:\n",
    "        if (e >= s) and (s%3 == 0):\n",
    "            orfs.append([s,e])\n",
    "    return orfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_genome(seq_record, dna):\n",
    "    # Get positive ORFs (coding sequences (CDS) or genes)\n",
    "    l_min = 50\n",
    "    cds = []\n",
    "    genes = []\n",
    "    for feature in seq_record.features:\n",
    "        if feature.type == 'CDS':\n",
    "            tag    = feature.qualifiers['locus_tag'][0]\n",
    "            start  = feature.location.start.position\n",
    "            end    = feature.location.end.position\n",
    "            strand = feature.strand\n",
    "            seq    = dna[0][start:end] if strand == 1 else dna[1][::-1][start:end][::-1]\n",
    "            \n",
    "            orfs = orf_finder(seq.seq)\n",
    "            \n",
    "            for i,orf in enumerate(orfs):\n",
    "                orf_start = orf[0] + start\n",
    "                orf_end = orf[1] + start\n",
    "                orf_tag = tag + '.' + str(i)\n",
    "                orf_seq = seq[orf[0]:orf[1]]\n",
    "                \n",
    "                if len(orf_seq) < l_min: continue\n",
    "                \n",
    "                f = [SeqFeature(FeatureLocation(orf_start, orf_end, strand), type=\"CDS\")]\n",
    "                r = SeqRecord(orf_seq.seq, name=orf_tag, id=prokaryote_id, features=f)\n",
    "                cds.append(r)\n",
    "                \n",
    "                if i == 0: genes.append(r)\n",
    "    \n",
    "    # Find interregions\n",
    "    interregions = get_interregions(genes)\n",
    "    \n",
    "    # Get negative ORFs(longest ORF in interregion)\n",
    "    ## interregion (intr)\n",
    "    ## longest orf (long)\n",
    "    \n",
    "    ncs = []\n",
    "    for interregion in interregions:\n",
    "        feature = interregion.features[0]\n",
    "        \n",
    "        tag    = interregion.name\n",
    "        start  = feature.location.start.position\n",
    "        end    = feature.location.end.position\n",
    "        strand = feature.strand\n",
    "        \n",
    "        intr_seq = dna[0][start:end] if strand == 1 else dna[1][::-1][start:end][::-1]\n",
    "        \n",
    "        long_orf = longest_orf(intr_seq.seq)\n",
    "        if not long_orf: continue\n",
    "        \n",
    "        long_seq = intr_seq[long_orf[0]:long_orf[1]]\n",
    "        long_start = start + long_orf[0]\n",
    "\n",
    "        # check to see if noncoding ORF is larger than l_min (smallest coding sequence length) \n",
    "        if len(long_seq) < l_min: continue\n",
    "        \n",
    "        orfs = orf_finder(long_seq.seq)\n",
    "        \n",
    "        for i, orf in enumerate(orfs):\n",
    "            if orf[1]-orf[0] < l_min: continue\n",
    "            \n",
    "            orf_start = long_start + orf[0]\n",
    "            orf_end = long_start + orf[1]\n",
    "            orf_tag = tag + '.' + str(i)\n",
    "            orf_seq = long_seq[orf[0]:orf[1]]\n",
    "            \n",
    "            f = [SeqFeature(FeatureLocation(orf_start, orf_end, strand), type=\"NCS\")]\n",
    "            r = SeqRecord(orf_seq.seq, name=prokaryote_id, id=orf_tag, features=f)\n",
    "            ncs.append(r)\n",
    "    \n",
    "    return cds, ncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC_000917 ORFs extracted -- 23.2528 seconds\n"
     ]
    }
   ],
   "source": [
    "prokaryote_ids = ['NC_000917']\n",
    "\n",
    "# get seq_records (features) from GenBank file\n",
    "handle = Entrez.efetch(db=\"sequences\", id=prokaryote_id, rettype=\"gbwithparts\", retmode=\"text\")\n",
    "seq_record = SeqIO.read(handle, \"gb\")\n",
    "handle.close()\n",
    "\n",
    "# get full sequence from FASTA file\n",
    "handle = Entrez.efetch(db=\"sequences\", id=prokaryote_id, rettype=\"fasta\", retmode=\"text\")\n",
    "sequence = SeqIO.read(handle, \"fasta\")\n",
    "handle.close()\n",
    "\n",
    "dna = [sequence, sequence.reverse_complement()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find ORFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC_000917 ORFs extracted -- 7.5554 seconds\n",
      "52161\n",
      "43505\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "cds, ncs = preprocess_genome(seq_record, dna)\n",
    "\n",
    "print('%s ORFs extracted -- %s seconds' % (prokaryote_id, round(time.time() - start_time, 4)))\n",
    "print(f'{len(cds)} CDS ORFs and {len(ncs)} NCS ORFs found -- {len(cds)+len(ncs)} total ORFs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF_NC00000.0 GTG TAA 4785 5025\n",
      "AF_NC00000.1 TTG TAA 4818 5025\n",
      "AF_NC00000.2 CTG TAA 4821 5025\n",
      "AF_NC00000.3 TTG TAA 4836 5025\n",
      "AF_NC00000.4 GTG TAA 4887 5025\n",
      "AF_NC00018.0 ATG TGA 25242 30024\n",
      "AF_NC00018.1 CTG TGA 25275 30024\n",
      "AF_NC00018.2 CTG TGA 25305 30024\n",
      "AF_NC00018.3 TTG TGA 25308 30024\n",
      "AF_NC00018.4 CTG TGA 25323 30024\n"
     ]
    }
   ],
   "source": [
    "# Check that noncoding ORFs start and end with correct codons\n",
    "for neg in ncs[0:10]:\n",
    "    print(neg.id, neg.seq[0:3], neg.seq[-3:], neg.features[0].location.start.position, neg.features[0].location.end.position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Monocodon (Tri) and Dicodon (Hex) Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produces all tri/hex codon permutations 4^n (ex. AAA, AAC,...,TTT for n=3) \n",
    "def permutations_with_replacement(n):\n",
    "    for i in itertools.product((\"A\", \"C\", \"G\", \"T\"), repeat=n):\n",
    "        yield i\n",
    "\n",
    "# Function to create codon:idx dictionary. Converts codons to integers\n",
    "def populate_codon_idx_dict(nbases=3):\n",
    "    codon_idx_dict = {}\n",
    "    count = 0\n",
    "    for i in permutations_with_replacement(nbases):\n",
    "        key = \"\".join(i) #codon or dicodon sequence\n",
    "        codon_idx_dict[key] = count\n",
    "        count += 1\n",
    "    return codon_idx_dict\n",
    "\n",
    "\n",
    "TRICODON_IDX_DICT = populate_codon_idx_dict(nbases=3)\n",
    "HEXCODON_IDX_DICT = populate_codon_idx_dict(nbases=6)\n",
    "\n",
    "\n",
    "# Parse dna sequence into a list of codons separated by nbases\n",
    "# Input: Bio.Seq.Seq\n",
    "'''\n",
    "Ex. Input  - AAATTTGGG\n",
    "    Output - ['AAA','TTT','GGG'] if nbases=3\n",
    "           = ['AAATTT']          if nbases=6\n",
    "'''\n",
    "def codon_parser(seq, nbases):\n",
    "    codon_seq = [seq[i:i+nbases] for i in range(0,len(seq),3) if (i+nbases)<len(seq)]\n",
    "    return codon_seq\n",
    "\n",
    "# Returns count of tri/hex codons in list form\n",
    "# Input: Bio.Seq.Seq\n",
    "def codon_feature(seq, nbases):      \n",
    "    codon_idx_dict = TRICODON_IDX_DICT if nbases==3 else HEXCODON_IDX_DICT\n",
    "    frame = [0]*len(codon_idx_dict)\n",
    "    \n",
    "    parsed_codons = codon_parser(seq, nbases)\n",
    "    for codon in parsed_codons:\n",
    "        frame[codon_idx_dict[codon]] += 1\n",
    "    frame[codon_idx_dict[parsed_codons[-1]]] += 1 # add last codon\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Translation Initiation Sites (TIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
